{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the specialities\n",
    "\n",
    "so that later there is a mapping table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pdfplumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "must start with CVK CCM CBF CBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'data/specialities/Kostenstellen OE.pdf'\n",
    "\n",
    "tables = []\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page in pdf.pages:\n",
    "        table = page.extract_table()\n",
    "        if table:\n",
    "            tables.append(table)\n",
    "\n",
    "# Combine tables if needed\n",
    "combined_table = pd.concat([pd.DataFrame(table[1:], columns=table[0]) for table in tables], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows with empty 'OE' values\n",
    "empty_OE_rows = combined_table[combined_table['OE'] == \"\"]\n",
    "\n",
    "# Select rows with non-empty 'OE' values\n",
    "non_empty_OE_rows = combined_table[combined_table['OE'] != \"\"]\n",
    "\n",
    "# Remove duplicates from non-empty 'OE' rows\n",
    "non_empty_OE_rows = non_empty_OE_rows.drop_duplicates(subset=['OE'])\n",
    "\n",
    "# Combine both dataframes back together\n",
    "combined_table = pd.concat([empty_OE_rows, non_empty_OE_rows])\n",
    "\n",
    "combined_table = combined_table.sort_index()\n",
    "\n",
    "combined_table = combined_table.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count rows in which 'CC' is empty\n",
    "\n",
    "# if >=2:\n",
    "# - take the second last row as title\n",
    "# - save all following OEs\n",
    "# - do this until there are again at least 2 empty rows\n",
    "# - the OEs then go into the dataset\n",
    "\n",
    "\n",
    "# Initialize list to collect data\n",
    "specialities_data = []\n",
    "\n",
    "currentlyAddingOEs = False\n",
    "\n",
    "currentSpeciality = None\n",
    "currentOEs = []\n",
    "\n",
    "for index, row in combined_table.iterrows():\n",
    "    cc = row['CC']\n",
    "    oe = row['OE']\n",
    "\n",
    "    if (cc == \"\" and oe == \"\"):\n",
    "        currentlyAddingOEs = False\n",
    "        continue\n",
    "\n",
    "    if not currentlyAddingOEs:\n",
    "        currentlyAddingOEs = True\n",
    "\n",
    "        cc_line_before = combined_table.at[index-1, 'CC']\n",
    "        cc_line_2_before = combined_table.at[index-2, 'CC']\n",
    "        oe_line_before = combined_table.at[index-1, 'OE']\n",
    "        oe_line_2_before = combined_table.at[index-2, 'OE']\n",
    "\n",
    "        if (cc_line_before == \"\") and (cc_line_2_before == \"\") and (oe_line_before == \"\") and (oe_line_2_before == \"\"):\n",
    "            if currentSpeciality is not None:\n",
    "                specialities_data.append({'speciality': currentSpeciality, 'OEs': currentOEs})\n",
    "            currentSpeciality = combined_table.at[index-2, 'KOSTENSTELLENSTRUKTUR']\n",
    "            currentOEs = []\n",
    "\n",
    "    if oe !=\"\":\n",
    "        currentOEs.append(oe)\n",
    "\n",
    "# Handle the last group\n",
    "specialities_data.append({'speciality': currentSpeciality, 'OEs': currentOEs})\n",
    "\n",
    "# Create DataFrame from accumulated data\n",
    "specialities = pd.DataFrame(specialities_data)\n",
    "\n",
    "# Now 'specialities' DataFrame contains the collected data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialities = specialities[specialities['OEs'].apply(lambda x: len(x) > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all campus occurences\n",
    "specialities['speciality'] = specialities['speciality'].str.replace(r'\\b(?:CCM|CVK|CBF|CBB|FL|DL)\\b/?', '', regex=True)\n",
    "#remove all multible whitespaces\n",
    "specialities['speciality'] = specialities['speciality'].str.replace(r'\\s+', ' ', regex=True)\n",
    "# remove all leading commas\n",
    "specialities['speciality'] = specialities['speciality'].str.lstrip(',')\n",
    "# remove all leading dots\n",
    "specialities['speciality'] = specialities['speciality'].str.lstrip('.')\n",
    "# remove all leading and trailing whitespaces\n",
    "specialities['speciality'] = specialities['speciality'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## take out everithing that connects data to the hospital\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken out to ensure data privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add manual specialities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manuals = pd.read_csv('data/specialities/manual_specialities.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_to_array(x):\n",
    "    return [x]\n",
    "manuals['OEs'] = manuals['OEs'].apply(string_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialities = pd.concat([specialities, manuals], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and going on with the processing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to concatenate lists\n",
    "def merge_OEs(list_of_lists):\n",
    "    merged = []\n",
    "    for sublist in list_of_lists:\n",
    "        merged.extend(sublist)\n",
    "    return merged\n",
    "\n",
    "# Group by 'speciality' and aggregate\n",
    "specialities = specialities.groupby('speciality').agg({'OEs': merge_OEs}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialities = specialities.sort_values('speciality').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # Adjust the number as needed\n",
    "pd.set_option('display.max_columns', None)  # Adjust the number as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change speciality names here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialities['speciality'].to_csv('data/out/specialities.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialities_exploded = specialities.explode('OEs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialities_exploded.to_pickle(\"data/specialities/specialities.pkl\")\n",
    "specialities_exploded.to_csv(\"data/specialities/specialities.csv\", index=False, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# adjust mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_table = pd.read_csv('data/specialities/speciality_mapping.csv', sep=';')\n",
    "maual_mapping_table = pd.read_csv('data/specialities/manual_speciality_mapping.csv', sep=';')\n",
    "mapping_table = pd.concat([mapping_table, maual_mapping_table], ignore_index=True)\n",
    "mapping_table.to_pickle(\"data/specialities/speciality_mapping.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
